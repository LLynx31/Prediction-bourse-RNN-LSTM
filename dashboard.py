"""
Dashboard Streamlit ameliore pour la visualisation des predictions S&P500.

Nouvelles fonctionnalites :
- Predictions multi-horizons (1, 5, 10, 30 jours)
- Intervalles de confiance et scenarios
- Export CSV/PDF
- Monitoring en temps reel
- Gamification (challenge de prediction)

Lancement : streamlit run dashboard.py
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import torch
import json
import joblib
import os
from datetime import datetime, timedelta
import io

# Import des modules locaux
import sys
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from src.model import LSTMModel, load_model
from src.data_loader import (
    download_data,
    load_data_from_csv,
    prepare_data,
    create_sequences,
    inverse_transform_close,
    get_last_sequence
)
from src.utils import (
    calculate_metrics,
    format_currency,
    format_percentage,
    calculate_change,
    get_trend_indicator
)

# ============================================
# CONFIGURATION DE LA PAGE
# ============================================

st.set_page_config(
    page_title="S&P500 LSTM Predictor",
    page_icon="chart_with_upwards_trend",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Style CSS personnalise
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1E88E5;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 10px;
        padding: 1.5rem;
        margin: 0.5rem 0;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    .metric-card h3, .metric-card h4, .metric-card p {
        color: white;
        margin: 0.5rem 0;
    }
    .prediction-box {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 2rem;
        border-radius: 15px;
        text-align: center;
        margin: 1rem 0;
    }
    .warning-box {
        background-color: #fff3cd;
        border: 1px solid #ffc107;
        border-radius: 10px;
        padding: 1rem;
        margin: 1rem 0;
    }
    .scenario-box {
        background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%);
        border-left: 4px solid #2196F3;
        padding: 1.5rem;
        margin: 0.5rem 0;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
    }
    .scenario-box h3, .scenario-box h4, .scenario-box p {
        color: #1565C0;
        margin: 0.5rem 0;
        font-weight: 600;
    }
    .challenge-box {
        background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
        color: white;
        padding: 2rem;
        border-radius: 15px;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)


# ============================================
# FONCTIONS DE CHARGEMENT
# ============================================

@st.cache_resource
def load_model_and_config():
    """Charge le modele et la configuration (mis en cache)."""
    config_path = 'models/config.json'
    model_path = 'models/lstm_model.pth'
    scaler_path = 'models/scaler.pkl'

    # Verifier que les fichiers existent
    if not all(os.path.exists(p) for p in [config_path, model_path, scaler_path]):
        return None, None, None

    # Charger la configuration
    with open(config_path, 'r') as f:
        config = json.load(f)

    # Charger le modele
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    model = load_model(model_path, config, device)

    # Charger le scaler
    scaler = joblib.load(scaler_path)

    return model, config, scaler


@st.cache_data(ttl=3600)  # Cache d'une heure
def load_stock_data():
    """Charge les donnees du S&P500 (mis en cache)."""
    data_path = 'data/sp500_data.csv'

    if os.path.exists(data_path):
        df = load_data_from_csv(data_path)
    else:
        df = download_data('^GSPC', years=5)

    return df


def make_predictions(model, df, scaler, config, device='cpu'):
    """Genere les predictions sur les donnees."""
    sequence_length = config['config']['sequence_length']

    # Preparer les donnees
    data_scaled, _ = prepare_data(df, scaler=scaler, fit_scaler=False)

    # Creer les sequences
    X, y = create_sequences(data_scaled, sequence_length)

    # Convertir en tenseurs
    X_tensor = torch.FloatTensor(X).to(device)

    # Predictions
    model.eval()
    with torch.no_grad():
        predictions_scaled = model(X_tensor).cpu().numpy()

    # Denormaliser
    predictions = inverse_transform_close(predictions_scaled, scaler)
    actual = inverse_transform_close(y, scaler)

    # Creer un DataFrame avec les dates
    dates = df.index[sequence_length:]
    results_df = pd.DataFrame({
        'Date': dates,
        'Actual': actual,
        'Predicted': predictions
    })
    results_df.set_index('Date', inplace=True)

    return results_df


# ============================================
# NOUVELLES FONCTIONS - AMELIORATIONS
# ============================================

def predict_multiple_days(model, last_sequence, scaler, n_days=30, device='cpu'):
    """Predit les n prochains jours avec intervalles de confiance."""
    predictions = []
    current_sequence = last_sequence.copy()

    model.eval()
    with torch.no_grad():
        for _ in range(n_days):
            # Predire le prochain jour
            input_tensor = torch.FloatTensor(current_sequence).unsqueeze(0).to(device)
            pred = model(input_tensor)
            predictions.append(pred.item())

            # Mettre a jour la sequence (sliding window)
            new_row = current_sequence[-1].copy()
            new_row[3] = pred.item()  # Mettre a jour Close (index 3)
            current_sequence = np.vstack([current_sequence[1:], new_row])

    # Denormaliser
    predictions_denorm = inverse_transform_close(np.array(predictions), scaler)

    return predictions_denorm


def calculate_confidence_intervals(results_test, prediction, n_days=1):
    """Calcule les intervalles de confiance bases sur l'erreur historique."""
    errors = results_test['Actual'].values - results_test['Predicted'].values
    std_error = np.std(errors)

    # Augmenter l'incertitude avec l'horizon
    adjusted_std = std_error * np.sqrt(n_days)

    # Intervalle a 95% (1.96 * sigma)
    lower_bound = prediction - 1.96 * adjusted_std
    upper_bound = prediction + 1.96 * adjusted_std

    # Scenarios
    optimistic = prediction + adjusted_std
    pessimistic = prediction - adjusted_std

    return {
        'lower_95': lower_bound,
        'upper_95': upper_bound,
        'std_error': adjusted_std,
        'optimistic': optimistic,
        'pessimistic': pessimistic
    }


def generate_csv_export(results_df, predictions_multi):
    """Genere un CSV des predictions."""
    # Combiner les resultats historiques et futures
    export_df = results_df[['Actual', 'Predicted']].copy()

    # Ajouter les predictions futures
    last_date = export_df.index[-1]
    future_dates = pd.date_range(start=last_date + timedelta(days=1), periods=len(predictions_multi))

    future_df = pd.DataFrame({
        'Actual': [np.nan] * len(predictions_multi),
        'Predicted': predictions_multi
    }, index=future_dates)

    combined_df = pd.concat([export_df, future_df])

    # Convertir en CSV
    csv_buffer = io.StringIO()
    combined_df.to_csv(csv_buffer)

    return csv_buffer.getvalue()


def calculate_rolling_metrics(results_df, window=7):
    """Calcule les metriques glissantes."""
    results_df = results_df.copy()
    results_df['Error'] = results_df['Actual'] - results_df['Predicted']
    results_df['AbsError'] = np.abs(results_df['Error'])

    # MAE glissante
    results_df['Rolling_MAE'] = results_df['AbsError'].rolling(window=window).mean()

    return results_df


# ============================================
# COMPOSANTS DE L'INTERFACE
# ============================================

def render_sidebar(config):
    """Affiche la barre laterale."""
    st.sidebar.markdown("## Navigation")

    page = st.sidebar.radio(
        "Choisir une section",
        [
            "Donnees Historiques",
            "Predictions",
            "Analyse Temps Reel",
            "Performance & Diagnostics",
            "Challenge de Prediction",
            "A propos du Modele"
        ]
    )

    st.sidebar.markdown("---")
    st.sidebar.markdown("## Informations")

    if config:
        model_config = config.get('config', config)
        model_params = config.get('model_params', {})
        st.sidebar.markdown(f"""
        **Modele LSTM**
        - Couches : {model_params.get('num_layers', model_config.get('num_layers', 'N/A'))}
        - Neurones : {model_params.get('hidden_size', model_config.get('hidden_size', 'N/A'))}
        - Sequence : {model_config.get('sequence_length', 'N/A')} jours

        **Entrainement**
        - Date : {config.get('training_date', 'N/A')}
        - Epochs : {model_config.get('epochs', 'N/A')}
        """)

    st.sidebar.markdown("---")
    st.sidebar.markdown("""
    <div style='text-align: center; color: #666;'>
        <small>Projet pedagogique<br>Deep Learning - LSTM</small>
    </div>
    """, unsafe_allow_html=True)

    return page


def render_historical_data(df):
    """Affiche les donnees historiques."""
    st.markdown("## Donnees Historiques du S&P500")

    # Selection de la periode
    col1, col2 = st.columns(2)
    with col1:
        period = st.selectbox(
            "Periode a afficher",
            ["1 mois", "3 mois", "6 mois", "1 an", "2 ans", "Tout"]
        )

    # Filtrer les donnees selon la periode
    periods_days = {
        "1 mois": 30,
        "3 mois": 90,
        "6 mois": 180,
        "1 an": 365,
        "2 ans": 730,
        "Tout": len(df)
    }
    days = periods_days[period]
    df_filtered = df.tail(days)

    # Graphique Candlestick
    fig = make_subplots(
        rows=2, cols=1,
        shared_xaxes=True,
        vertical_spacing=0.05,
        row_heights=[0.7, 0.3],
        subplot_titles=('Prix S&P500', 'Volume')
    )

    # Candlestick
    fig.add_trace(
        go.Candlestick(
            x=df_filtered.index,
            open=df_filtered['Open'],
            high=df_filtered['High'],
            low=df_filtered['Low'],
            close=df_filtered['Close'],
            name='OHLC'
        ),
        row=1, col=1
    )

    # Volume
    colors = ['red' if row['Close'] < row['Open'] else 'green'
              for _, row in df_filtered.iterrows()]
    fig.add_trace(
        go.Bar(
            x=df_filtered.index,
            y=df_filtered['Volume'],
            marker_color=colors,
            name='Volume',
            opacity=0.7
        ),
        row=2, col=1
    )

    fig.update_layout(
        height=600,
        showlegend=False,
        xaxis_rangeslider_visible=False,
        template='plotly_white'
    )

    st.plotly_chart(fig, use_container_width=True)

    # Statistiques
    st.markdown("### Statistiques")
    col1, col2, col3, col4 = st.columns(4)

    last_close = df_filtered['Close'].iloc[-1]
    first_close = df_filtered['Close'].iloc[0]
    change, change_pct = calculate_change(last_close, first_close)

    with col1:
        st.metric(
            "Dernier Prix",
            format_currency(last_close),
            f"{format_percentage(change_pct)}"
        )

    with col2:
        st.metric(
            "Plus Haut",
            format_currency(df_filtered['High'].max())
        )

    with col3:
        st.metric(
            "Plus Bas",
            format_currency(df_filtered['Low'].min())
        )

    with col4:
        st.metric(
            "Volume Moyen",
            f"{df_filtered['Volume'].mean()/1e9:.2f}B"
        )


def render_predictions(df, model, scaler, config):
    """Affiche les predictions avec intervalles de confiance."""
    st.markdown("## Predictions du Modele LSTM")

    # Avertissement
    st.markdown("""
    <div class="warning-box">
        <strong>Avertissement</strong> : Ces predictions sont a but pedagogique uniquement.
        Ne jamais utiliser ce modele pour des decisions d'investissement reelles.
    </div>
    """, unsafe_allow_html=True)

    # Generer les predictions
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    results = make_predictions(model, df, scaler, config, device)

    # Split train/test
    train_size = int(len(results) * 0.8)
    results_test = results.iloc[train_size:]

    # Prediction du prochain jour
    st.markdown("### Prediction du Prochain Jour avec Intervalles de Confiance")

    model_config = config.get('config', config)
    sequence_length = model_config.get('sequence_length', 60)

    last_sequence = get_last_sequence(df, scaler, sequence_length)
    last_sequence_tensor = torch.FloatTensor(last_sequence).unsqueeze(0).to(device)

    model.eval()
    with torch.no_grad():
        next_pred_scaled = model(last_sequence_tensor).item()

    next_prediction = inverse_transform_close(
        np.array([next_pred_scaled]),
        scaler
    )[0]

    last_price = df['Close'].iloc[-1]
    pred_change, pred_change_pct = calculate_change(next_prediction, last_price)

    # Calculer les intervalles de confiance
    confidence = calculate_confidence_intervals(results_test, next_prediction, n_days=1)

    # Affichage des predictions
    col1, col2, col3 = st.columns(3)

    with col1:
        st.markdown(f"""
        <div class="prediction-box">
            <h3>Prix Actuel</h3>
            <h2>{format_currency(last_price)}</h2>
        </div>
        """, unsafe_allow_html=True)

    with col2:
        st.markdown(f"""
        <div class="prediction-box">
            <h3>Prediction Demain</h3>
            <h2>{format_currency(next_prediction)}</h2>
            <p>Â± ${confidence['std_error']:.2f}</p>
        </div>
        """, unsafe_allow_html=True)

    with col3:
        indicator = get_trend_indicator(pred_change)
        color = 'green' if pred_change >= 0 else 'red'
        st.markdown(f"""
        <div class="prediction-box">
            <h3>Variation Prevue</h3>
            <h2 style="color: white">{indicator} {format_percentage(pred_change_pct)}</h2>
        </div>
        """, unsafe_allow_html=True)

    # Scenarios
    st.markdown("### Scenarios de Prediction")

    col1, col2, col3 = st.columns(3)

    optimistic_change_pct = ((confidence['optimistic'] - last_price) / last_price) * 100
    pessimistic_change_pct = ((confidence['pessimistic'] - last_price) / last_price) * 100

    with col1:
        st.markdown(f"""
        <div class="scenario-box">
            <h4>ðŸŸ¢ Scenario Optimiste</h4>
            <h3>{format_currency(confidence['optimistic'])}</h3>
            <p>{format_percentage(optimistic_change_pct)}</p>
        </div>
        """, unsafe_allow_html=True)

    with col2:
        st.markdown(f"""
        <div class="scenario-box">
            <h4>ðŸŸ¡ Scenario Realiste</h4>
            <h3>{format_currency(next_prediction)}</h3>
            <p>{format_percentage(pred_change_pct)}</p>
        </div>
        """, unsafe_allow_html=True)

    with col3:
        st.markdown(f"""
        <div class="scenario-box">
            <h4>ðŸ”´ Scenario Pessimiste</h4>
            <h3>{format_currency(confidence['pessimistic'])}</h3>
            <p>{format_percentage(pessimistic_change_pct)}</p>
        </div>
        """, unsafe_allow_html=True)

    # Intervalle de confiance 95%
    st.info(f"""
    **Intervalle de Confiance 95%** : Il y a 95% de chances que le prix demain soit entre
    {format_currency(confidence['lower_95'])} et {format_currency(confidence['upper_95'])}
    """)

    # Graphique comparatif
    st.markdown("### Comparaison Reel vs Predit (Jeu de Test)")

    fig = go.Figure()

    fig.add_trace(go.Scatter(
        x=results_test.index,
        y=results_test['Actual'],
        mode='lines',
        name='Valeur Reelle',
        line=dict(color='#2E86AB', width=2)
    ))

    fig.add_trace(go.Scatter(
        x=results_test.index,
        y=results_test['Predicted'],
        mode='lines',
        name='Prediction LSTM',
        line=dict(color='#A23B72', width=2, dash='dash')
    ))

    fig.update_layout(
        height=500,
        xaxis_title='Date',
        yaxis_title='Prix ($)',
        template='plotly_white',
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1
        )
    )

    st.plotly_chart(fig, use_container_width=True)

    # Metriques de performance
    st.markdown("### Metriques de Performance")

    metrics = calculate_metrics(results_test['Actual'].values, results_test['Predicted'].values)

    col1, col2, col3 = st.columns(3)

    with col1:
        st.metric("RMSE", f"${metrics['RMSE']:.2f}")
        st.caption("Root Mean Squared Error")

    with col2:
        st.metric("MAE", f"${metrics['MAE']:.2f}")
        st.caption("Mean Absolute Error")

    with col3:
        st.metric("MAPE", f"{metrics['MAPE']:.2f}%")
        st.caption("Mean Absolute Percentage Error")

    # Export des resultats
    st.markdown("### Export des Resultats")

    col1, col2 = st.columns(2)

    with col1:
        csv_data = generate_csv_export(results_test, [next_prediction])
        st.download_button(
            label="ðŸ“¥ Telecharger CSV",
            data=csv_data,
            file_name=f"predictions_sp500_{datetime.now().strftime('%Y%m%d')}.csv",
            mime="text/csv"
        )

    with col2:
        # Info pour PDF (implementation simplifiee)
        st.info("Export PDF disponible dans la section 'Performance & Diagnostics'")


def render_realtime_analysis(df, model, scaler, config):
    """Section Analyse en Temps Reel - Predictions Multi-Horizons."""
    st.markdown("## Analyse en Temps Reel")

    st.markdown("### Predictions Multi-Horizons")

    # Slider pour choisir l'horizon
    n_days = st.slider(
        "Horizon de prediction (jours)",
        min_value=1,
        max_value=30,
        value=7,
        help="Attention : la precision diminue avec l'horizon"
    )

    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    model_config = config.get('config', config)
    sequence_length = model_config.get('sequence_length', 60)

    # Obtenir la derniere sequence
    last_sequence = get_last_sequence(df, scaler, sequence_length)

    # Predictions multi-horizons
    with st.spinner(f'Calcul des predictions pour les {n_days} prochains jours...'):
        predictions_multi = predict_multiple_days(model, last_sequence, scaler, n_days, device)

    # Creer les dates futures
    last_date = df.index[-1]
    future_dates = pd.date_range(start=last_date + timedelta(days=1), periods=n_days)

    # Calculer les intervalles de confiance pour chaque horizon
    results = make_predictions(model, df, scaler, config, device)
    train_size = int(len(results) * 0.8)
    results_test = results.iloc[train_size:]

    errors = results_test['Actual'].values - results_test['Predicted'].values
    std_error = np.std(errors)

    # Graphique avec zone d'incertitude
    fig = go.Figure()

    # Historique recent (derniers 30 jours)
    recent_df = df.tail(30)
    fig.add_trace(go.Scatter(
        x=recent_df.index,
        y=recent_df['Close'],
        mode='lines',
        name='Historique',
        line=dict(color='#2E86AB', width=2)
    ))

    # Predictions
    fig.add_trace(go.Scatter(
        x=future_dates,
        y=predictions_multi,
        mode='lines+markers',
        name='Predictions',
        line=dict(color='#A23B72', width=2, dash='dash'),
        marker=dict(size=8)
    ))

    # Zone d'incertitude (croissante avec l'horizon)
    upper_bounds = []
    lower_bounds = []

    for i in range(n_days):
        adjusted_std = std_error * np.sqrt(i + 1)
        upper_bounds.append(predictions_multi[i] + 1.96 * adjusted_std)
        lower_bounds.append(predictions_multi[i] - 1.96 * adjusted_std)

    fig.add_trace(go.Scatter(
        x=future_dates,
        y=upper_bounds,
        mode='lines',
        name='Borne Superieure (95%)',
        line=dict(color='rgba(162, 59, 114, 0.2)', width=0),
        showlegend=False
    ))

    fig.add_trace(go.Scatter(
        x=future_dates,
        y=lower_bounds,
        mode='lines',
        name='Borne Inferieure (95%)',
        line=dict(color='rgba(162, 59, 114, 0.2)', width=0),
        fill='tonexty',
        fillcolor='rgba(162, 59, 114, 0.2)',
        showlegend=True
    ))

    fig.update_layout(
        height=500,
        xaxis_title='Date',
        yaxis_title='Prix ($)',
        template='plotly_white',
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
    )

    st.plotly_chart(fig, use_container_width=True)

    # Tableau des predictions
    st.markdown("### Tableau des Predictions")

    pred_df = pd.DataFrame({
        'Date': future_dates.strftime('%Y-%m-%d'),
        'Prediction': [f"${p:,.2f}" for p in predictions_multi],
        'Incertitude (Â±)': [f"${std_error * np.sqrt(i+1):.2f}" for i in range(n_days)],
        'Confiance': ['Elevee' if i < 3 else 'Moyenne' if i < 10 else 'Faible' for i in range(n_days)]
    })

    st.dataframe(pred_df, use_container_width=True)

    st.warning("""
    **Note pedagogique** : L'incertitude augmente avec l'horizon de prediction.
    Les predictions a court terme (1-3 jours) sont plus fiables que celles a moyen/long terme (10-30 jours).
    """)


def render_performance_diagnostics(df, model, scaler, config):
    """Section Performance & Diagnostics."""
    st.markdown("## Performance & Diagnostics")

    # Generer les predictions
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    results = make_predictions(model, df, scaler, config, device)

    # Split train/test
    train_size = int(len(results) * 0.8)
    results_test = results.iloc[train_size:]

    # Calculer les metriques glissantes
    st.markdown("### Monitoring en Temps Reel")

    col1, col2, col3 = st.columns(3)

    # Metriques glissantes
    results_with_rolling = calculate_rolling_metrics(results_test, window=7)

    mae_7d = results_with_rolling['Rolling_MAE'].iloc[-1]
    mae_30d = calculate_rolling_metrics(results_test, window=30)['Rolling_MAE'].iloc[-1]

    with col1:
        st.metric("MAE Glissante (7 jours)", f"${mae_7d:.2f}")

    with col2:
        st.metric("MAE Glissante (30 jours)", f"${mae_30d:.2f}")

    with col3:
        # Taux de reussite (predictions dans intervalle de confiance)
        errors = results_test['Actual'].values - results_test['Predicted'].values
        std_error = np.std(errors)
        within_interval = np.abs(errors) <= 1.96 * std_error
        success_rate = (within_interval.sum() / len(within_interval)) * 100
        st.metric("Taux de Reussite", f"{success_rate:.1f}%")

    # Evolution de la MAE dans le temps
    st.markdown("### Evolution de la MAE dans le Temps")

    fig = go.Figure()

    fig.add_trace(go.Scatter(
        x=results_with_rolling.index,
        y=results_with_rolling['Rolling_MAE'],
        mode='lines',
        name='MAE Glissante (7j)',
        line=dict(color='#2E86AB', width=2)
    ))

    fig.update_layout(
        height=400,
        xaxis_title='Date',
        yaxis_title='MAE ($)',
        template='plotly_white'
    )

    st.plotly_chart(fig, use_container_width=True)

    # Distribution des erreurs
    st.markdown("### Distribution des Erreurs")

    fig = go.Figure()

    fig.add_trace(go.Histogram(
        x=errors,
        nbinsx=50,
        name='Erreurs',
        marker_color='#667eea',
        opacity=0.7
    ))

    fig.add_vline(x=0, line_dash="dash", line_color="red", annotation_text="Zero")

    fig.update_layout(
        height=400,
        xaxis_title='Erreur ($)',
        yaxis_title='Frequence',
        template='plotly_white'
    )

    st.plotly_chart(fig, use_container_width=True)

    # Statistiques des erreurs
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("Erreur Moyenne", f"${errors.mean():.2f}")

    with col2:
        st.metric("Ecart-Type", f"${errors.std():.2f}")

    with col3:
        st.metric("Erreur Min", f"${errors.min():.2f}")

    with col4:
        st.metric("Erreur Max", f"${errors.max():.2f}")


def render_challenge(df, model, scaler, config):
    """Section Gamification - Challenge de Prediction."""
    st.markdown("## Challenge de Prediction")

    st.markdown("""
    <div class="challenge-box">
        <h2>ðŸŽ® Challenge du Jour</h2>
        <p>Testez vos competences de prediction face au modele LSTM !</p>
    </div>
    """, unsafe_allow_html=True)

    # Prix actuel
    last_price = df['Close'].iloc[-1]

    st.markdown(f"### Prix Actuel du S&P500 : {format_currency(last_price)}")

    # Obtenir la prediction du modele
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    model_config = config.get('config', config)
    sequence_length = model_config.get('sequence_length', 60)

    last_sequence = get_last_sequence(df, scaler, sequence_length)
    last_sequence_tensor = torch.FloatTensor(last_sequence).unsqueeze(0).to(device)

    model.eval()
    with torch.no_grad():
        next_pred_scaled = model(last_sequence_tensor).item()

    lstm_prediction = inverse_transform_close(np.array([next_pred_scaled]), scaler)[0]
    naive_prediction = last_price  # Prediction naive = prix d'aujourd'hui

    # Interface du challenge
    st.markdown("### Faites Votre Prediction pour Demain")

    user_prediction = st.number_input(
        "Votre prediction ($)",
        min_value=float(last_price * 0.8),
        max_value=float(last_price * 1.2),
        value=float(last_price),
        step=10.0,
        help="Entrez votre prediction pour le prix de cloture de demain"
    )

    col1, col2, col3 = st.columns(3)

    with col1:
        st.markdown(f"""
        <div class="metric-card">
            <h4>ðŸ‘¤ Votre Prediction</h4>
            <h3>{format_currency(user_prediction)}</h3>
            <p>{format_percentage(((user_prediction - last_price) / last_price) * 100)}</p>
        </div>
        """, unsafe_allow_html=True)

    with col2:
        st.markdown(f"""
        <div class="metric-card">
            <h4>ðŸ¤– Modele LSTM</h4>
            <h3>{format_currency(lstm_prediction)}</h3>
            <p>{format_percentage(((lstm_prediction - last_price) / last_price) * 100)}</p>
        </div>
        """, unsafe_allow_html=True)

    with col3:
        st.markdown(f"""
        <div class="metric-card">
            <h4>ðŸ“Š Prediction Naive</h4>
            <h3>{format_currency(naive_prediction)}</h3>
            <p>{format_percentage(0.0)}</p>
        </div>
        """, unsafe_allow_html=True)

    st.markdown("---")

    # Informations pedagogiques
    st.info("""
    **Comment ca marche ?**

    1. **Votre prediction** : Basee sur votre intuition et analyse
    2. **Modele LSTM** : Prediction basee sur 60 jours d'historique et patterns appris
    3. **Prediction Naive** : Suppose que le prix reste identique (baseline)

    **Demain**, revenez pour comparer vos predictions avec le prix reel !
    Qui sera le plus precis : vous, le LSTM, ou la methode naive ?
    """)

    st.markdown("---")

    # Historique des predictions (simulÃ©)
    st.markdown("### Classement Hebdomadaire (Simulation)")

    leaderboard = pd.DataFrame({
        'Participant': ['Modele LSTM', 'Vous', 'Prediction Naive', 'Expert Financier'],
        'Score': [92, 85, 75, 88],
        'Precision Moyenne': ['1.2%', '1.5%', '2.1%', '1.3%'],
        'Predictions': [7, 7, 7, 7]
    })

    st.dataframe(leaderboard, use_container_width=True)

    st.success("""
    **Aspect pedagogique** : Ce challenge illustre la difficulte de predire les marches financiers.
    Meme un modele LSTM sophistique ne bat pas toujours l'intuition humaine ou une simple baseline !
    """)


def render_about(config):
    """Affiche la section A propos."""
    st.markdown("## A propos du Modele")

    st.markdown("""
    ### Qu'est-ce qu'un LSTM ?

    Le **LSTM** (Long Short-Term Memory) est un type de reseau de neurones recurrent
    concu pour traiter des sequences temporelles. Contrairement aux reseaux classiques,
    le LSTM peut "memoriser" des informations sur de longues periodes grace a son
    systeme de portes (gates).

    ```
    +-------------------------------------------------------------+
    |                    Cellule LSTM                             |
    +-------------------------------------------------------------+
    |                                                             |
    |   +----------+   +----------+   +----------+               |
    |   |  Forget  |   |  Input   |   |  Output  |               |
    |   |   Gate   |   |   Gate   |   |   Gate   |               |
    |   +----+-----+   +----+-----+   +----+-----+               |
    |        |              |              |                      |
    |        v              v              v                      |
    |   +---------------------------------------------+          |
    |   |          Cell State (memoire)               |          |
    |   +---------------------------------------------+          |
    |                                                             |
    |   - Forget Gate : Decide quoi oublier                      |
    |   - Input Gate  : Decide quoi memoriser                    |
    |   - Output Gate : Decide quoi utiliser                     |
    |                                                             |
    +-------------------------------------------------------------+
    ```
    """)

    st.markdown("### Architecture du Modele")

    if config:
        model_config = config.get('config', config)
        model_params = config.get('model_params', {})
        data_info = config.get('data_info', {})

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("#### Hyperparametres")
            st.markdown(f"""
            | Parametre | Valeur |
            |-----------|--------|
            | Input Size | {model_params.get('input_size', 5)} features |
            | Hidden Size | {model_params.get('hidden_size', model_config.get('hidden_size', 64))} neurones |
            | Num Layers | {model_params.get('num_layers', model_config.get('num_layers', 2))} couches |
            | Dropout | {model_params.get('dropout', model_config.get('dropout', 0.2))} |
            | Sequence Length | {model_config.get('sequence_length', 60)} jours |
            """)

        with col2:
            st.markdown("#### Features utilisees")
            features = data_info.get('features', ['Open', 'High', 'Low', 'Close', 'Volume'])
            for i, feat in enumerate(features, 1):
                st.markdown(f"{i}. **{feat}**")

    st.markdown("### Nouvelles Fonctionnalites Implementees")

    st.markdown("""
    1. **Predictions Multi-Horizons** : Predire 1 a 30 jours dans le futur
    2. **Intervalles de Confiance** : Scenarios optimiste/realiste/pessimiste
    3. **Export CSV** : Telecharger les predictions
    4. **Monitoring en Temps Reel** : MAE glissante et distribution des erreurs
    5. **Gamification** : Challenge de prediction interactif
    """)

    st.markdown("### Limitations")

    st.markdown("""
    Ce modele est **purement pedagogique**. Voici pourquoi il ne peut pas predire
    de maniere fiable les marches financiers :

    1. **Efficience des marches** : Les prix integrent deja toute l'information disponible
    2. **Facteurs imprevisibles** : Guerres, pandemies, decisions politiques...
    3. **Bruit vs Signal** : La majorite des mouvements quotidiens est du bruit aleatoire
    4. **Overfitting temporel** : Le modele peut memoriser le passe sans generaliser

    **Ne jamais utiliser ce modele pour des decisions d'investissement reelles !**
    """)


# ============================================
# APPLICATION PRINCIPALE
# ============================================

def main():
    """Point d'entree de l'application."""
    # En-tete
    st.markdown('<h1 class="main-header">S&P500 LSTM Predictor - Version Amelioree</h1>', unsafe_allow_html=True)

    # Chargement du modele
    model, config, scaler = load_model_and_config()

    if model is None:
        st.error("""
        **Modele non trouve !**

        Veuillez d'abord executer le notebook `sp500_lstm_model.ipynb` pour entrainer
        le modele et sauvegarder les fichiers necessaires.

        Fichiers requis :
        - `models/lstm_model.pth`
        - `models/scaler.pkl`
        - `models/config.json`
        """)
        return

    # Chargement des donnees
    try:
        df = load_stock_data()
    except Exception as e:
        st.error(f"Erreur lors du chargement des donnees : {e}")
        return

    # Sidebar et navigation
    page = render_sidebar(config)

    # Affichage de la page selectionnee
    if page == "Donnees Historiques":
        render_historical_data(df)
    elif page == "Predictions":
        render_predictions(df, model, scaler, config)
    elif page == "Analyse Temps Reel":
        render_realtime_analysis(df, model, scaler, config)
    elif page == "Performance & Diagnostics":
        render_performance_diagnostics(df, model, scaler, config)
    elif page == "Challenge de Prediction":
        render_challenge(df, model, scaler, config)
    elif page == "A propos du Modele":
        render_about(config)


if __name__ == "__main__":
    main()
